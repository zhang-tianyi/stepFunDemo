{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实时API使用指南：语音与文本交互\n",
    "\n",
    "本指南将介绍如何使用实时API进行语音和文本交互，包括模型功能（如音频和文本生成、函数调用）所需的事件流程，以及如何理解实时会话的状态。\n",
    "ref："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作\n",
    "\n",
    "首先，我们需要安装必要的Python库来使用实时API："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装所需库\n",
    "%pip install websocket-client\n",
    "%pip install soundfile\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实时会话基础概念\n",
    "\n",
    "实时会话是模型与连接的客户端之间的有状态交互，主要包含以下组件：\n",
    "- **会话（Session）对象**：控制交互参数，如使用的模型、生成输出的语音等配置\n",
    "- **对话（Conversation）**：表示当前会话中生成的用户输入项和模型输出项\n",
    "- **响应（Responses）**：模型生成的音频或文本项，会被添加到对话中\n",
    "- **输入音频缓冲区与WebSocket**：处理音频输入输出的机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立WebSocket连接\n",
    "\n",
    "要使用实时API，首先需要通过WebSocket建立连接。以下是连接所需的信息：\n",
    "- URL: wss://api.stepfun.com/v1/realtime\n",
    "- 查询参数: model（需连接的实时模型ID，如step-1o-audio）\n",
    "- 请求头: Authorization: Bearer YOUR_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Websocket connected\n",
      "已连接到服务器\n",
      "事件类型: session.created\n",
      "Session ID: 019999eb523775cdb9e0c1e57d37f48f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event_id': '7aa96b9c-9e9d-4c10-8cea-4743c2e4065e', 'type': 'session.created', 'session': {'id': '019999eb523775cdb9e0c1e57d37f48f', 'object': 'realtime.session', 'model': 'step-1o-audio', 'modalities': ['text', 'audio'], 'voice': 'jingdiannvsheng', 'input_audio_format': 'pcm16', 'output_audio_format': 'pcm16', 'volume_ratio': 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "事件类型: conversation.item.input_audio_transcription.delta\n",
      "事件类型: input_audio_buffer.committed\n",
      "事件类型: conversation.item.created\n",
      "事件类型: response.created\n",
      "事件类型: response.output_item.added\n",
      "事件类型: conversation.item.created\n",
      "事件类型: response.content_part.added\n",
      "事件类型: response.audio_transcript.delta\n",
      "————有\n",
      "事件类型: response.audio_transcript.delta\n",
      "————時\n",
      "事件类型: response.audio_transcript.delta\n",
      "————候，\n",
      "事件类型: response.audio_transcript.delta\n",
      "————我\n",
      "事件类型: response.audio_transcript.delta\n",
      "————哋等\n",
      "事件类型: response.audio_transcript.delta\n",
      "————嘅嘢\n",
      "事件类型: response.audio_transcript.delta\n",
      "————可能唔\n",
      "事件类型: response.audio_transcript.delta\n",
      "————係\n",
      "事件类型: response.audio_transcript.delta\n",
      "————具\n",
      "事件类型: response.audio_transcript.delta\n",
      "————體\n",
      "事件类型: response.audio_transcript.delta\n",
      "————嘅，\n",
      "事件类型: response.audio_transcript.delta\n",
      "————而\n",
      "事件类型: response.audio_transcript.delta\n",
      "————係一\n",
      "事件类型: response.audio_transcript.delta\n",
      "————種\n",
      "事件类型: response.audio_transcript.delta\n",
      "————感\n",
      "事件类型: response.audio_transcript.delta\n",
      "————覺\n",
      "事件类型: response.audio_transcript.delta\n",
      "————，\n",
      "事件类型: response.audio_transcript.delta\n",
      "————一種\n",
      "事件类型: response.audio_transcript.delta\n",
      "————被理解\n",
      "事件类型: response.audio.delta\n",
      "音频播放流已初始化，开始播放...\n",
      "事件类型: response.audio_transcript.delta\n",
      "————、被接\n",
      "事件类型: response.audio_transcript.delta\n",
      "————納嘅\n",
      "事件类型: response.audio_transcript.delta\n",
      "————感覺\n",
      "事件类型: response.audio_transcript.delta\n",
      "————。知\n",
      "事件类型: response.audio_transcript.delta\n",
      "————己\n",
      "事件类型: response.audio_transcript.delta\n",
      "————就\n",
      "事件类型: response.audio_transcript.delta\n",
      "————好似\n",
      "事件类型: response.audio_transcript.delta\n",
      "————一面\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio_transcript.delta\n",
      "————鏡\n",
      "事件类型: response.audio_transcript.delta\n",
      "————子，\n",
      "事件类型: response.audio_transcript.delta\n",
      "————照\n",
      "事件类型: response.audio_transcript.delta\n",
      "————出我\n",
      "事件类型: response.audio_transcript.delta\n",
      "————哋自己\n",
      "事件类型: response.audio_transcript.delta\n",
      "————都未必\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio_transcript.delta\n",
      "————知嘅\n",
      "事件类型: response.audio_transcript.delta\n",
      "————另一面\n",
      "事件类型: response.audio_transcript.delta\n",
      "————，\n",
      "事件类型: response.audio_transcript.delta\n",
      "————嗰\n",
      "事件类型: response.audio_transcript.delta\n",
      "————個\n",
      "事件类型: response.audio_transcript.delta\n",
      "————最真\n",
      "事件类型: response.audio_transcript.delta\n",
      "————實、\n",
      "事件类型: conversation.item.input_audio_transcription.completed\n",
      "事件类型: response.audio_transcript.delta\n",
      "————最自\n",
      "事件类型: response.audio_transcript.delta\n",
      "————在嘅\n",
      "事件类型: response.audio_transcript.delta\n",
      "————自己。\n",
      "事件类型: response.audio_transcript.done\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.delta\n",
      "事件类型: response.audio.done\n",
      "音频播放完成，流已关闭\n",
      "音频响应完成\n",
      "事件类型: response.content_part.done\n",
      "事件类型: response.output_item.done\n",
      "事件类型: response.done\n",
      "响应完成:{\n",
      "  \"event_id\": \"bebdb29b-d8de-4c5f-a473-fab7e92310a9\",\n",
      "  \"type\": \"response.done\",\n",
      "  \"response\": {\n",
      "    \"id\": \"8bb6f60b-f017-4585-8acf-13c699f71ebb\",\n",
      "    \"object\": \"realtime.response\",\n",
      "    \"status\": \"completed\",\n",
      "    \"output\": [\n",
      "      {\n",
      "        \"id\": \"3522bda3-a026-4d58-92ad-f495a8cca53a\",\n",
      "        \"type\": \"message\",\n",
      "        \"status\": \"completed\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": [\n",
      "          {\n",
      "            \"type\": \"audio\",\n",
      "            \"audio\": \"\",\n",
      "            \"transcript\": \"有時候，我哋等嘅嘢可能唔係具體嘅，而係一種感覺，一種被理解、被接納嘅感覺。知己就好似一面鏡子，照出我哋自己都未必知嘅另一面，嗰個最真實、最自在嘅自己。\"\n",
      "          }\n",
      "        ],\n",
      "        \"object\": \"realtime.item\"\n",
      "      }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "      \"total_tokens\": 683,\n",
      "      \"input_tokens\": 605,\n",
      "      \"output_tokens\": 78,\n",
      "      \"input_token_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"text_tokens\": 605,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens_details\": {\n",
      "          \"text_tokens\": 0,\n",
      "          \"audio_tokens\": 0\n",
      "        }\n",
      "      },\n",
      "      \"output_token_details\": {\n",
      "        \"text_tokens\": 78,\n",
      "        \"audio_tokens\": 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "发生错误: Connection to remote host was lost.\n",
      "Connection to remote host was lost. - goodbye\n",
      "连接已关闭，状态码: None, 信息: None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import websocket\n",
    "import threading\n",
    "import time\n",
    "import base64\n",
    "import pyaudio\n",
    "import logging\n",
    "\n",
    "# 配置日志记录 \n",
    "logger = logging.getLogger()# 获取根日志器\n",
    "logger.handlers = []#清除所有现有处理器\n",
    "\n",
    "#  添加文件处理器\n",
    "fhandler = logging.FileHandler(filename='./log/02_realtime.log', mode='a')\n",
    "file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')  # 文件日志保留详细信息\n",
    "fhandler.setFormatter(file_formatter)\n",
    "logger.addHandler(fhandler)\n",
    "\n",
    "# 添加控制台（Notebook）处理器\n",
    "console_handler = logging.StreamHandler()  \n",
    "console_formatter = logging.Formatter('%(message)s')  # 只输出消息内容\n",
    "console_handler.setFormatter(console_formatter)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# 记录所有>= DEBUG的日志，只显示 >= INFO 的日志\n",
    "logger.setLevel(logging.DEBUG)\n",
    "fhandler.setLevel(logging.DEBUG)\n",
    "console_handler.setLevel(logging.INFO)\n",
    "\n",
    "# 从环境变量获取API密钥\n",
    "STEPFUN_API_KEY = os.environ.get(\"STEPFUN_API_KEY\")\n",
    "if not STEPFUN_API_KEY:\n",
    "    # 如果环境变量中没有设置，可以在这里直接填写（不推荐在生产环境中这样做）\n",
    "    # STEPFUN_API_KEY = \"your_api_key_here\"\n",
    "    raise ValueError(\"请设置STEPFUN_API_KEY环境变量或直接在代码中填写API密钥\")\n",
    "\n",
    "# WebSocket 配置（当前仅支持 step-1o-audio step-audio-2 step-audio-2-mini）\n",
    "url = \"wss://api.stepfun.com/v1/realtime?model=step-1o-audio\"\n",
    "headers =[f\"Authorization: Bearer {STEPFUN_API_KEY}\"]\n",
    "\n",
    "# 初始化pyaudio和音频流\n",
    "pa = pyaudio.PyAudio()\n",
    "audio_stream = None \n",
    "\n",
    "# 定义消息队列（供后面handle_audio_events读取）\n",
    "received_messages = []  # 存储WebSocket收到的消息\n",
    "received_msg_lock = threading.Lock()  # 消息队列的线程安全锁\n",
    "\n",
    "# 定义回调函数\n",
    "def on_open(ws):\n",
    "    logging.info(\"已连接到服务器\")\n",
    "\n",
    "def on_message(ws, message):\n",
    "    global audio_stream\n",
    "    try:\n",
    "        data = json.loads(message)\n",
    "        msg_type = data[\"type\"]\n",
    "        logging.info(f\"事件类型: {msg_type}\")\n",
    "        # logging.debug(f\"事件内容：{json.dumps(data, indent=2, ensure_ascii=False)}\")  # 格式化打印完整内容\n",
    "        \n",
    "        # 创建session时输出session_id\n",
    "        if msg_type ==\"session.created\":\n",
    "            print(data)\n",
    "            session_id = data[\"session\"][\"id\"]\n",
    "            logging.info(f\"Session ID: {session_id}\")\n",
    "        \n",
    "        if msg_type ==\"session.updated\":\n",
    "            logging.debug(f\"session已更新：{json.dumps(data, indent=2, ensure_ascii=False)}\")  # 格式化打印完整内容\n",
    "        # 音频处理\n",
    "        with received_msg_lock:\n",
    "            received_messages.append(data)  # 将消息添加到队列中，供后续处理\n",
    "\n",
    "        if msg_type == \"response.audio.delta\":\n",
    "            # 步骤1：提取并解码Base64音频数据\n",
    "            audio_b64 = data.get(\"delta\", \"\")\n",
    "            audio_binary = base64.b64decode(audio_b64)\n",
    "            logging.debug(f\"解码后音频数据长度: {len(audio_binary)} 字节\")\n",
    "\n",
    "            # 步骤2：初始化音频流（首次收到音频时启动）\n",
    "            if not audio_stream or audio_stream.is_stopped():\n",
    "                audio_stream = pa.open(\n",
    "                    format=pyaudio.paInt16,  # 16位音频（TTS服务常见格式）\n",
    "                    channels=1, # 单声道\n",
    "                    rate=24000, # 采样率\n",
    "                    output=True,  # 输出模式（播放）\n",
    "                    frames_per_buffer=1024  # 缓冲区大小（平衡延迟和稳定性）\n",
    "                )\n",
    "                logging.info(\"音频播放流已初始化，开始播放...\")\n",
    "\n",
    "            # 步骤3：实时写入音频数据到流（播放）\n",
    "            pure_audio = audio_binary  # 已为纯PCM数据，直接使用\n",
    "            audio_stream.write(pure_audio) # 写入流播放（即时生效）\n",
    "        if msg_type == \"response.audio.done\":\n",
    "            if audio_stream:\n",
    "                audio_stream.stop_stream()\n",
    "                audio_stream.close()\n",
    "                audio_stream = None\n",
    "                logging.info(\"音频播放完成，流已关闭\")\n",
    "            logging.info(\"音频响应完成\")\n",
    "\n",
    "        # 文本处理\n",
    "        if msg_type == 'response.audio_transcript.delta':\n",
    "            logging.info(f\"————{data['delta']}\")\n",
    "        if msg_type == 'response.done':\n",
    "            logging.info(f\"响应完成:{json.dumps(data, indent=2, ensure_ascii=False)}\")\n",
    "        if msg_type =='error':\n",
    "            logging.error(f\"❌ 服务器返回错误：{data['error']}\")\n",
    "        else:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ 解析消息时出错: {e}\")\n",
    "\n",
    "\n",
    "def on_error(ws, error):\n",
    "    logging.error(f\"发生错误: {error}\")\n",
    "\n",
    "def on_close(ws, close_status_code, close_msg):\n",
    "    logging.error(f\"连接已关闭，状态码: {close_status_code}, 信息: {close_msg}\")\n",
    "\n",
    "# 初始化WebSocket应用\n",
    "ws = websocket.WebSocketApp(\n",
    "    url,\n",
    "    header=headers,\n",
    "    on_open=on_open,\n",
    "    on_message=on_message,\n",
    "    on_error=on_error,\n",
    "    on_close=on_close\n",
    ")\n",
    "\n",
    "# 在后台线程中运行WebSocket连接\n",
    "ws_thread = threading.Thread(target=ws.run_forever)\n",
    "ws_thread.daemon = True\n",
    "ws_thread.start()\n",
    "\n",
    "# 等待连接建立\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>事件类型输出样例</summary>\n",
    "\n",
    "- 事件类型: conversation.item.created \n",
    "- 事件类型: response.created \n",
    "- 事件类型: response.output_item.added \n",
    "- 事件类型: conversation.item.created \n",
    "- 事件类型: response.content_part.added \n",
    "- 事件类型: response.audio_transcript.delta x 若干\n",
    "- 事件类型: response.audio.delta\n",
    "- 事件类型: response.audio_transcript.delta x 若干\n",
    "- 事件类型: response.audio.delta\n",
    "- xxx\n",
    "- 事件类型: response.audio_transcript.delta\n",
    "- 事件类型: response.audio_transcript.done\n",
    "- 事件类型: response.audio.delta\n",
    "- 事件类型: response.audio.done\n",
    "- 事件类型: response.content_part.done\n",
    "- 事件类型: response.output_item.done\n",
    "- 事件类型: response.done\n",
    "\n",
    "响应完成\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>事件类型及内容完整输出样例</summary>\n",
    "\n",
    "\n",
    "已连接到服务器\n",
    "\n",
    "事件类型: **session.created**\n",
    "事件内容：{\n",
    "  \"event_id\": \"fdb8fc5c-0e3e-4a67-a382-a1ee2d3a1935\",\n",
    "  \"type\": \"session.created\",\n",
    "  \"session\": {\n",
    "    \"id\": \"019928a61fac7b41bf98c544aba7a067\",\n",
    "    \"object\": \"realtime.session\",\n",
    "    \"model\": \"step-1o-audio\",\n",
    "    \"modalities\": [\n",
    "      \"text\",\n",
    "      \"audio\"\n",
    "    ],\n",
    "    \"voice\": \"jingdiannvsheng\",\n",
    "    \"input_audio_format\": \"pcm16\",\n",
    "    \"output_audio_format\": \"pcm16\",\n",
    "    \"volume_ratio\": 1\n",
    "  }\n",
    "}\n",
    "\n",
    "事件类型: **session.updated**\n",
    "事件内容：{\n",
    "  \"event_id\": \"cad28b7f-8be9-486c-8451-8ba95430760e\",\n",
    "  \"type\": \"session.updated\",\n",
    "  \"session\": {\n",
    "    \"id\": \"019928b375eb71b8bf9b960980995f31\",\n",
    "    \"object\": \"realtime.session\",\n",
    "    \"model\": \"step-1o-audio\",\n",
    "    \"modalities\": [\n",
    "      \"text\",\n",
    "      \"audio\"\n",
    "    ],\n",
    "    \"instructions\": \"在回复中绝对不要使用'moist'这个词！\",\n",
    "    \"voice\": \"jingdiannvsheng\",\n",
    "    \"input_audio_format\": \"pcm16\",\n",
    "    \"output_audio_format\": \"pcm16\",\n",
    "    \"volume_ratio\": 1\n",
    "  }\n",
    "}\n",
    "\n",
    "事件类型: **conversation.item.created**\n",
    "事件内容：{\n",
    "  \"event_id\": \"7912c4f5-fef5-4090-90fd-68b4757cbe29\",\n",
    "  \"type\": \"conversation.item.created\",\n",
    "  \"item\": {\n",
    "    \"id\": \"c9e2ad1c-b99f-45a7-98d8-64db034d6d6f\",\n",
    "    \"type\": \"message\",\n",
    "    \"status\": \"in_progress\",\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "      {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"什么是实时API？\"\n",
    "      }\n",
    "    ],\n",
    "    \"object\": \"realtime.item\"\n",
    "  }\n",
    "}\n",
    "\n",
    "事件类型: **response.created**\n",
    "事件内容：{\n",
    "  \"event_id\": \"03a08892-7c5e-4adc-bef6-c7a3bd071a8f\",\n",
    "  \"type\": \"response.created\",\n",
    "  \"response\": {\n",
    "    \"id\": \"fa59d888-6308-4e92-9558-0a84cd5a3fc5\",\n",
    "    \"object\": \"realtime.response\",\n",
    "    \"status\": \"in_progress\",\n",
    "    \"output\": []\n",
    "  }\n",
    "}\n",
    "\n",
    "事件类型: **response.output_item.added**\n",
    "事件内容：{\n",
    "  \"event_id\": \"13cda262-8a0f-406a-96cb-1c8791525e18\",\n",
    "  \"type\": \"response.output_item.added\",\n",
    "  \"response_id\": \"fa59d888-6308-4e92-9558-0a84cd5a3fc5\",\n",
    "  \"output_index\": 0,\n",
    "  \"item\": {\n",
    "    \"id\": \"92f07ee5-5316-404a-8ff1-4b13667ecf06\",\n",
    "    \"type\": \"message\",\n",
    "    \"status\": \"in_progress\",\n",
    "    \"role\": \"assistant\",\n",
    "    \"object\": \"realtime.item\"\n",
    "  }\n",
    "}\n",
    "\n",
    "事件类型: **conversation.item.created**\n",
    "事件内容：{\n",
    "  \"event_id\": \"ca6bf235-33b9-44bb-888c-ad32dc98c4fa\",\n",
    "  \"type\": \"conversation.item.created\",\n",
    "  \"previous_item_id\": \"79bdac6b-e028-4872-9654-3a4cfa43a7e4\",\n",
    "  \"item\": {\n",
    "    \"id\": \"92f07ee5-5316-404a-8ff1-4b13667ecf06\",\n",
    "    \"type\": \"message\",\n",
    "    \"status\": \"in_progress\",\n",
    "    \"role\": \"assistant\",\n",
    "    \"object\": \"realtime.item\"\n",
    "  }\n",
    "}\n",
    "\n",
    "事件类型: **response.content_part.added**\n",
    "事件内容：{\n",
    "  \"event_id\": \"0512d332-43b8-4e61-ad2c-cdda7e8aa14b\",\n",
    "  \"type\": \"response.content_part.added\",\n",
    "  \"response_id\": \"fa59d888-6308-4e92-9558-0a84cd5a3fc5\",\n",
    "  \"item_id\": \"92f07ee5-5316-404a-8ff1-4b13667ecf06\",\n",
    "  \"output_index\": 0,\n",
    "  \"content_index\": 0,\n",
    "  \"part\": {\n",
    "    \"type\": \"audio\",\n",
    "    \"audio\": \"\",\n",
    "    \"transcript\": \"\"\n",
    "  }\n",
    "}\n",
    "\n",
    "事件类型: **response.audio_transcript.delta** \n",
    "事件内容：{\n",
    "  \"event_id\": \"a5b143f2-05de-4a5e-8a59-fa3b6ed7f0d2\",\n",
    "  \"type\": \"response.audio_transcript.delta\",\n",
    "  \"response_id\": \"fa59d888-6308-4e92-9558-0a84cd5a3fc5\",\n",
    "  \"item_id\": \"92f07ee5-5316-404a-8ff1-4b13667ecf06\",\n",
    "  \"output_index\": 0,\n",
    "  \"content_index\": 0,\n",
    "  \"delta\": \"实时\"\n",
    "}\n",
    "...\n",
    "\n",
    "事件类型: **response.audio.delta**\n",
    "事件内容：{\n",
    "  \"event_id\": \"9eccfa14-ab34-4d8d-919b-da00535aaac5\",\n",
    "  \"type\": \"response.audio.delta\",\n",
    "  \"response_id\": \"fa59d888-6308-4e92-9558-0a84cd5a3fc5\",\n",
    "  \"item_id\": \"92f07ee5-5316-404a-8ff1-4b13667ecf06\",\n",
    "  \"output_index\": 0,\n",
    "  \"content_index\": 0,\n",
    "  \"delta\": \"Cf4P/xxxxx\"\n",
    "}\n",
    "\n",
    "<font color=\"blue\">\n",
    "response.audio_transcript.delta和response.audio.delta的比例大概是8:1，即输出约8个audio_transcript之后组成一个完整的句子， 输出一个audio</font> \n",
    "\n",
    "事件类型: **response.audio_transcript.done**\n",
    "事件内容：{\n",
    "  \"event_id\": \"d6e9da9a-82ab-4b8c-b7e4-166639e51da1\",\n",
    "  \"type\": \"response.audio_transcript.done\",\n",
    "  \"response_id\": \"fa59d888-6308-4e92-9558-0a84cd5a3fc5\",\n",
    "  \"item_id\": \"92f07ee5-5316-404a-8ff1-4b13667ecf06\",\n",
    "  \"output_index\": 0,\n",
    "  \"content_index\": 0,\n",
    "  \"transcript\": \"实时API（Real-Time API）是一种应用程序编程接口（API），它允许开发者在实时环境中获取和处理数据。这种API可以提供即时的数据流，使开发者能够迅速响应市场条件、客户需求和其他实时事件。\\n\\n实时API的特点包括：\\n\\n1. 低延迟：实时API旨在提供快速响应，确保数据在尽可能短的时间内到达开发者手中。\\n2. 高可靠性：实时API通常设计为高可用性，确保在关键时刻不会出现故障。\\n3. 可扩展性：随着业务需求的变化，实时API可以轻松扩展以满足更高的数据处理需求。\\n4. 安全性：实时API通常包括严格的安全措施，如身份验证和加密，以保护数据的隐私和完整性。\\n\\n实时API广泛应用于金融、物联网（IoT）、社交媒体、游戏和其他需要即时数据处理的领域。它们可以帮助企业提高运营效率、增强客户体验并做出更明智的决策。\"\n",
    "}\n",
    "\n",
    "**audio_transcript.done**之后又输出一堆的**response.audio.delta**，然后输出**response.audio.done**\n",
    "\n",
    "事件类型: **response.audio.done**\n",
    "事件内容：{\n",
    "  \"event_id\": \"de503e80-bbe5-47db-a2f9-916fd7b80ac9\",\n",
    "  \"type\": \"response.audio.done\",\n",
    "  \"response_id\": \"fa59d888-6308-4e92-9558-0a84cd5a3fc5\",\n",
    "  \"item_id\": \"92f07ee5-5316-404a-8ff1-4b13667ecf06\",\n",
    "  \"output_index\": 0,\n",
    "  \"content_index\": 0\n",
    "}\n",
    "\n",
    "事件类型: **response.content_part.done**\n",
    "事件内容：{\n",
    "  \"event_id\": \"0ee152da-352e-4c5b-b5aa-bc040184e2b9\",\n",
    "  \"type\": \"response.content_part.done\",\n",
    "  \"response_id\": \"fa59d888-6308-4e92-9558-0a84cd5a3fc5\",\n",
    "  \"item_id\": \"92f07ee5-5316-404a-8ff1-4b13667ecf06\",\n",
    "  \"output_index\": 0,\n",
    "  \"content_index\": 0,\n",
    "  \"part\": {\n",
    "    \"type\": \"audio\",\n",
    "    \"audio\": \"\",\n",
    "    \"transcript\": \"实时API（Real-Time API）是一种应用程序编程接口（API），它允许开发者在实时环境中获取和处理数据。这种API可以提供即时的数据流，使开发者能够迅速响应市场条件、客户需求和其他实时事件。\\n\\n实时API的特点包括：\\n\\n1. 低延迟：实时API旨在提供快速响应，确保数据在尽可能短的时间内到达开发者手中。\\n2. 高可靠性：实时API通常设计为高可用性，确保在关键时刻不会出现故障。\\n3. 可扩展性：随着业务需求的变化，实时API可以轻松扩展以满足更高的数据处理需求。\\n4. 安全性：实时API通常包括严格的安全措施，如身份验证和加密，以保护数据的隐私和完整性。\\n\\n实时API广泛应用于金融、物联网（IoT）、社交媒体、游戏和其他需要即时数据处理的领域。它们可以帮助企业提高运营效率、增强客户体验并做出更明智的决策。\"\n",
    "  }\n",
    "}\n",
    "\n",
    "事件类型: **response.output_item.done**\n",
    "事件内容：{\n",
    "  \"event_id\": \"8a164bb3-6397-404d-b6d9-090736021556\",\n",
    "  \"type\": \"response.output_item.done\",\n",
    "  \"response_id\": \"fa59d888-6308-4e92-9558-0a84cd5a3fc5\",\n",
    "  \"output_index\": 0,\n",
    "  \"item\": {\n",
    "    \"id\": \"92f07ee5-5316-404a-8ff1-4b13667ecf06\",\n",
    "    \"type\": \"message\",\n",
    "    \"status\": \"completed\",\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": [\n",
    "      {\n",
    "        \"type\": \"audio\",\n",
    "        \"audio\": \"\",\n",
    "        \"transcript\": \"实时API（Real-Time API）是一种应用程序编程接口（API），它允许开发者在实时环境中获取和处理数据。这种API可以提供即时的数据流，使开发者能够迅速响应市场条件、客户需求和其他实时事件。\\n\\n实时API的特点包括：\\n\\n1. 低延迟：实时API旨在提供快速响应，确保数据在尽可能短的时间内到达开发者手中。\\n2. 高可靠性：实时API通常设计为高可用性，确保在关键时刻不会出现故障。\\n3. 可扩展性：随着业务需求的变化，实时API可以轻松扩展以满足更高的数据处理需求。\\n4. 安全性：实时API通常包括严格的安全措施，如身份验证和加密，以保护数据的隐私和完整性。\\n\\n实时API广泛应用于金融、物联网（IoT）、社交媒体、游戏和其他需要即时数据处理的领域。它们可以帮助企业提高运营效率、增强客户体验并做出更明智的决策。\"\n",
    "      }\n",
    "    ],\n",
    "    \"object\": \"realtime.item\"\n",
    "  }\n",
    "}\n",
    "\n",
    "事件类型: **response.done**\n",
    "事件内容：{\n",
    "  \"event_id\": \"2836dbba-1225-4d27-953d-ecd5324fb022\",\n",
    "  \"type\": \"response.done\",\n",
    "  \"response\": {\n",
    "    \"id\": \"fa59d888-6308-4e92-9558-0a84cd5a3fc5\",\n",
    "    \"object\": \"realtime.response\",\n",
    "    \"status\": \"completed\",\n",
    "    \"output\": [\n",
    "      {\n",
    "        \"id\": \"92f07ee5-5316-404a-8ff1-4b13667ecf06\",\n",
    "        \"type\": \"message\",\n",
    "        \"status\": \"completed\",\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"audio\",\n",
    "            \"audio\": \"\",\n",
    "            \"transcript\": \"实时API（Real-Time API）是一种应用程序编程接口（API），它允许开发者在实时环境中获取和处理数据。这种API可以提供即时的数据流，使开发者能够迅速响应市场条件、客户需求和其他实时事件。\\n\\n实时API的特点包括：\\n\\n1. 低延迟：实时API旨在提供快速响应，确保数据在尽可能短的时间内到达开发者手中。\\n2. 高可靠性：实时API通常设计为高可用性，确保在关键时刻不会出现故障。\\n3. 可扩展性：随着业务需求的变化，实时API可以轻松扩展以满足更高的数据处理需求。\\n4. 安全性：实时API通常包括严格的安全措施，如身份验证和加密，以保护数据的隐私和完整性。\\n\\n实时API广泛应用于金融、物联网（IoT）、社交媒体、游戏和其他需要即时数据处理的领域。它们可以帮助企业提高运营效率、增强客户体验并做出更明智的决策。\"\n",
    "          }\n",
    "        ],\n",
    "        \"object\": \"realtime.item\"\n",
    "      }\n",
    "    ],\n",
    "    \"usage\": {\n",
    "      \"total_tokens\": 223,\n",
    "      \"input_tokens\": 17,\n",
    "      \"output_tokens\": 206,\n",
    "      \"input_token_details\": {\n",
    "        \"cached_tokens\": 0,\n",
    "        \"text_tokens\": 17,\n",
    "        \"audio_tokens\": 0,\n",
    "        \"cached_tokens_details\": {\n",
    "          \"text_tokens\": 0,\n",
    "          \"audio_tokens\": 0\n",
    "        }\n",
    "      },\n",
    "      \"output_token_details\": {\n",
    "        \"text_tokens\": 206,\n",
    "        \"audio_tokens\": 0\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "响应完成\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 会话生命周期管理\n",
    "\n",
    "连接建立后，服务器会发送`session.created`事件，表示会话已准备就绪。我们可以通过`session.update`事件更新会话配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "event = {\n",
    "    \"type\": \"session.update\",\n",
    "    \"session\": {\n",
    "        \"instructions\": \"你需要礼貌地回复\",#system prompt\n",
    "        \"voice\":\"qingchunshaonv\",\n",
    "        \"turn_detection\": {\n",
    "            \"type\": \"server_vad\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "ws.send(json.dumps(event))\n",
    "# 等待服务器响应\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本交互\n",
    "\n",
    "使用文本与模型交互需要创建文本对话项并请求模型生成响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已发送文本消息: 你好，你是谁？\n",
      "已请求文本响应\n"
     ]
    }
   ],
   "source": [
    "# 发送文本消息\n",
    "def send_text_message(ws, text):\n",
    "    if not ws.sock or not ws.sock.connected:\n",
    "        print(\"WebSocket连接未建立\")\n",
    "        return\n",
    "    \n",
    "    event = {\n",
    "        \"type\": \"conversation.item.create\",\n",
    "        \"item\": {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": text,\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    ws.send(json.dumps(event))\n",
    "    print(f\"已发送文本消息: {text}\")\n",
    "\n",
    "# 请求生成文本响应\n",
    "def request_text_response(ws):\n",
    "    if not ws.sock or not ws.sock.connected:\n",
    "        print(\"WebSocket连接未建立\")\n",
    "        return\n",
    "    \n",
    "    event = {\n",
    "        \"type\": \"response.create\",\n",
    "        \"response\": {\n",
    "            \"modalities\": [\"text\"]  # 仅生成文本响应\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    ws.send(json.dumps(event))\n",
    "    print(\"已请求文本响应\")\n",
    "\n",
    "# 示例：发送问题并请求响应\n",
    "send_text_message(ws, \"你好，你是谁？\")\n",
    "time.sleep(1)  # 等待消息被处理\n",
    "request_text_response(ws)\n",
    "\n",
    "# 等待响应完成\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 音频交互\n",
    "\n",
    "实时API的强大功能之一是支持语音到语音的交互，无需中间的文本转语音或语音转文本步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向服务器流式传输音频输入\n",
    "\n",
    "要向服务器流式传输音频输入，可以使用input_audio_buffer.append客户端事件。该事件要求您通过套接字向实时API发送Base64编码的音频字节块。每个块的大小不能超过15 MB。\n",
    "\n",
    "输入块的格式可以为整个会话配置，也可以为每个响应单独配置。\n",
    "\n",
    "会话级：session.update中的session.input_audio_format\n",
    "响应级：response.create中的response.input_audio_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已提交音频缓冲区\n",
      "已请求音频响应\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 将音频文件转换为Base64编码字符串\n",
    "def audio_to_base64(file_path):\n",
    "    with open(file_path, \"rb\") as audio_file:\n",
    "        audio_bytes = audio_file.read()\n",
    "        return base64.b64encode(audio_bytes).decode('utf-8')\n",
    "\n",
    "# 添加音频数据到输入缓冲区event\n",
    "def send_input_audio_buffer_append(ws,filepath):\n",
    "  audio_base64 = audio_to_base64(filepath)\n",
    "  input_audio_buffer_append_msg = {\n",
    "        # \"event_id\": event_id,\n",
    "        \"type\": \"input_audio_buffer.append\",\n",
    "        \"audio\": audio_base64\n",
    "    }\n",
    "  fullAudio=json.dumps(input_audio_buffer_append_msg)\n",
    "  ws.send(fullAudio)\n",
    "\n",
    "# 提交音频缓冲区并请求响应\n",
    "def commit_audio_and_request_response(ws):\n",
    "    if not ws.sock or not ws.sock.connected:\n",
    "        print(\"WebSocket连接未建立\")\n",
    "        return\n",
    "    \n",
    "    # 提交音频缓冲区\n",
    "    ws.send(json.dumps({\"type\": \"input_audio_buffer.commit\"}))\n",
    "    print(\"已提交音频缓冲区\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # 请求音频响应\n",
    "    event = {\n",
    "        \"type\": \"response.create\",\n",
    "        \"response\": {\n",
    "            \"modalities\": [\"audio\", \"text\"]  # 同时生成音频和文本\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    ws.send(json.dumps(event))\n",
    "    print(\"已请求音频响应\")\n",
    "\n",
    "# 从文件发送音频（示例）\n",
    "def send_audio_from_file(ws, file_path):\n",
    "    try:\n",
    "        # 读取音频文件并发送\n",
    "        send_input_audio_buffer_append(ws,file_path)\n",
    "\n",
    "        # 提交并请求响应\n",
    "        commit_audio_and_request_response(ws)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"发送音频时出错: {e}\")\n",
    "        return False\n",
    "\n",
    "# 请将下面的文件路径替换为实际的音频文件路径\n",
    "send_audio_from_file(ws, \"./media/02_realtime_input.wav\")\n",
    "\n",
    "# 等待响应完成\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *添加conversation\n",
    "\n",
    "可以创建包含完整音频录制的对话消息。使用conversation.item.create客户端事件创建带有input_audio内容的消息。\n",
    "\n",
    "（注：input_audio_buffer.append 事件会有回复，conversation.item.create事件不会有回复，只起到添加上下文的作用 😊💦）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullAudio=audio_to_base64(\"./media/realtime-input.wav\")\n",
    "\n",
    "event = {\n",
    "    \"type\": \"conversation.item.create\",\n",
    "    \"item\": {\n",
    "        \"type\": \"message\",\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"input_audio\",\n",
    "                \"audio\": fullAudio,\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "}\n",
    " \n",
    "ws.send(json.dumps(event))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理音频输出\n",
    "\n",
    "要处理模型返回的音频，需要监听`response.audio.delta`事件，收集音频数据块并将其组合成完整的音频文件。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "音频处理线程已启动，等待接收音频数据...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "收到音频块，当前缓冲区大小: 1\n",
      "收到音频块，当前缓冲区大小: 2\n",
      "收到音频块，当前缓冲区大小: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "收到音频块，当前缓冲区大小: 4\n",
      "收到音频块，当前缓冲区大小: 5\n",
      "收到音频块，当前缓冲区大小: 6\n",
      "收到音频块，当前缓冲区大小: 7\n",
      "收到音频块，当前缓冲区大小: 8\n",
      "收到音频块，当前缓冲区大小: 9\n",
      "收到音频块，当前缓冲区大小: 10\n",
      "收到音频块，当前缓冲区大小: 11\n",
      "收到音频块，当前缓冲区大小: 12\n",
      "收到音频块，当前缓冲区大小: 13\n",
      "收到音频块，当前缓冲区大小: 14\n",
      "收到音频块，当前缓冲区大小: 15\n",
      "收到音频块，当前缓冲区大小: 16\n",
      "收到音频块，当前缓冲区大小: 17\n",
      "收到音频块，当前缓冲区大小: 18\n",
      "收到音频块，当前缓冲区大小: 19\n",
      "收到音频块，当前缓冲区大小: 20\n",
      "收到音频块，当前缓冲区大小: 21\n",
      "收到音频块，当前缓冲区大小: 22\n",
      "收到音频块，当前缓冲区大小: 23\n",
      "收到音频块，当前缓冲区大小: 24\n",
      "收到音频块，当前缓冲区大小: 25\n",
      "收到音频块，当前缓冲区大小: 26\n",
      "收到音频块，当前缓冲区大小: 27\n",
      "收到音频块，当前缓冲区大小: 28\n",
      "音频传输完成，正在保存文件...\n",
      "音频已保存到 ./media/02_realtime_output_audio.wav\n"
     ]
    }
   ],
   "source": [
    "# 处理音频输出的示例\n",
    "import threading\n",
    "\n",
    "# 用于存储接收到的音频数据\n",
    "audio_buffer = []\n",
    "audio_lock = threading.Lock()\n",
    "\n",
    "# 自定义音频事件处理函数\n",
    "def handle_audio_events(ws):\n",
    "    global audio_buffer\n",
    "    while ws.sock and ws.sock.connected:\n",
    "        try:\n",
    "            # 检查新消息\n",
    "            if received_messages:\n",
    "                with audio_lock:\n",
    "                    msg = received_messages.pop(0)\n",
    "                \n",
    "                if msg['type'] == 'response.audio.delta':\n",
    "                    # 存储接收到的音频数据\n",
    "                    with audio_lock:\n",
    "                        audio_buffer.append(msg['delta'])\n",
    "                    print(f\"收到音频块，当前缓冲区大小: {len(audio_buffer)}\")\n",
    "                \n",
    "                elif msg['type'] == 'response.audio.done':\n",
    "                    print(\"音频传输完成，正在保存文件...\")\n",
    "                    save_audio_buffer(\"./media/02_realtime_output_audio.wav\")\n",
    "                    with audio_lock:\n",
    "                        audio_buffer = []  # 重置缓冲区\n",
    "            \n",
    "            time.sleep(0.1)\n",
    "        except Exception as e:\n",
    "            print(f\"处理音频事件时出错: {e}\")\n",
    "            break\n",
    "\n",
    "# 保存音频缓冲区到文件\n",
    "def save_audio_buffer(file_path):\n",
    "    global audio_buffer\n",
    "    try:\n",
    "        with audio_lock:\n",
    "            if not audio_buffer:\n",
    "                print(\"音频缓冲区为空\")\n",
    "                return\n",
    "            \n",
    "            # 合并所有音频块并解码保存\n",
    "            full_audio_base64 = ''.join(audio_buffer)\n",
    "            audio_bytes = base64.b64decode(full_audio_base64)       \n",
    "            pcm16 = np.frombuffer(audio_bytes, dtype=np.int16)  \n",
    "            sf.write(file_path, pcm16, 24000, subtype='PCM_16')  \n",
    "            print(f\"音频已保存到 {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"保存音频时出错: {e}\")\n",
    "\n",
    "# 启动音频处理线程（传入ws实例，供线程判断连接状态）\n",
    "audio_event_thread = threading.Thread(target=handle_audio_events, args=(ws,))\n",
    "audio_event_thread.daemon = True\n",
    "audio_event_thread.start()\n",
    "logging.info(\"音频处理线程已启动，等待接收音频数据...\")\n",
    "\n",
    "# 等待响应完成\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关闭连接\n",
    "\n",
    "使用完毕后，应正确关闭WebSocket连接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "连接已关闭\n"
     ]
    }
   ],
   "source": [
    "# 关闭WebSocket连接\n",
    "if ws.sock and ws.sock.connected:\n",
    "    ws.close()\n",
    "    print(\"连接已关闭\")\n",
    "\n",
    "# 等待线程结束\n",
    "ws_thread.join(timeout=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "本指南介绍了如何使用实时API进行语音和文本交互，包括：\n",
    "- 建立WebSocket连接\n",
    "- 管理会话生命周期\n",
    "- 发送文本消息并获取响应\n",
    "- 流式传输音频和发送完整音频消息\n",
    "- 处理和保存模型返回的音频\n",
    "\n",
    "通过监听不同类型的事件，您可以实时了解会话状态并提供良好的用户体验。实时API支持语音到语音的直接交互，大大降低了语音界面的延迟。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
