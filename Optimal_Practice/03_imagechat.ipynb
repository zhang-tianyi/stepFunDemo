{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "StepFun 图片理解最佳实践（Jupyter 笔记）\n",
        "\n",
        "本笔记基于 StepFun 官方文档“图片理解最佳实践”，整理了常用用法与示例代码，方便快速上手与复用。\n",
        "\n",
        "参考文档：\n",
        "- [图片理解最佳实践](https://platform.stepfun.com/docs/guide/image_chat)\n",
        "\n",
        "内容涵盖：\n",
        "- 简单图片理解（传入单张图片）\n",
        "- 多轮对话与多图描述策略\n",
        "- `detail` 参数的使用（low/high）\n",
        "- 图片优化（resize、压缩）以降低首字延时\n",
        "- 透明 PNG 适配（RGBA 转 RGB 白底）\n",
        "- 以 Base64 方式传图\n",
        "- 常见问题与限制说明\n",
        "\n",
        "> 目前推荐使用 step-1o-turbo-vision 模型。该模型拥有最强的视频理解能力，推荐开启high detail 模式。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "地点识别结果：\n",
            "这张图片展示了一些装在白色碗里的蔬菜，摆放在木质桌面上。图片中并没有提供任何关于具体位置、城市、国家或地标建筑等地点信息的线索。图片主要聚焦于食物，背景是普通的木质桌面，没有其他环境或背景信息可以帮助识别具体地点。\n",
            "\n",
            "### **分析图片内容：**\n",
            "图片中展示了 **9种不同的蔬菜**，分别放在 **9个白色碗** 里，排列成 **3x3的方阵**。这些蔬菜包括：\n",
            "1. **左上角**：小土豆\n",
            "2. **中上**：芦笋\n",
            "3. **右上角**：红萝卜（可能是樱桃萝卜）\n",
            "4. **左边中间**：红辣椒\n",
            "5. **中间**：玉米笋\n",
            "6. **右边中间**：抱子甘蓝\n",
            "7. **左下角**：西兰花\n",
            "8. **中下**：樱桃番茄\n",
            "9. **右下角**：花菜\n",
            "\n",
            "### **关于地点信息：**\n",
            "图片中没有任何可以明确指出具体位置、城市或国家的元素，也没有任何地标建筑或环境特征。图片的右下角有水印，显示 **“©百家号/视觉中国”**，这表明图片可能来自视觉中国的图库，但并不提供关于拍摄地点的信息。\n",
            "\n",
            "### **结论：**\n",
            "这张图片是一个**食物展示图**，很可能是在室内拍摄的，背景是木质桌面，没有提供任何关于具体位置、城市、国家或地标建筑的详细信息。如果需要使用这张图片，可能与健康饮食、蔬菜分类或烹饪相关的内容有关。\n",
            "\n",
            "如果你需要这张图片的来源信息，可以尝试通过水印中的“视觉中国”图库进行搜索，但图片本身不包含任何地点信息。\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import base64\n",
        "from openai import OpenAI\n",
        "\n",
        "# 配置 API 密钥\n",
        "STEP_API_KEY = os.getenv(\"STEPFUN_API_KEY\")\n",
        "BASE_URL = \"https://api.stepfun.com/v1\"\n",
        "\n",
        "# 初始化客户端\n",
        "client = OpenAI(api_key=STEP_API_KEY, base_url=BASE_URL)\n",
        "\n",
        "def recognize_location_from_image(image_path):\n",
        "    \"\"\"\n",
        "    上传图片识别地点信息\n",
        "    \"\"\"\n",
        "    # 将图片转换为 Base64\n",
        "    def image_to_base64(image_path):\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            encoded_string = base64.b64encode(image_file.read())\n",
        "        return encoded_string.decode('utf-8')\n",
        "    \n",
        "    # 转换图片\n",
        "    image_b64 = image_to_base64(image_path)\n",
        "    \n",
        "    # 构造消息\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpg;base64,{image_b64}\",\n",
        "                        \"detail\": \"high\"  # 高精度模式，识别更准确\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"帮我识别这张图片中的地点信息，包括：具体位置、城市、国家、地标建筑等详细信息\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    try:\n",
        "        # 调用视觉理解模型\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"step-1o-turbo-vision\",  # 推荐使用视觉理解模型\n",
        "            messages=messages,\n",
        "            max_tokens=500\n",
        "        )\n",
        "        \n",
        "        return completion.choices[0].message.content\n",
        "        \n",
        "    except Exception as e:\n",
        "        return f\"识别失败：{str(e)}\"\n",
        "\n",
        "# 使用示例\n",
        "if __name__ == \"__main__\":\n",
        "    image_path = \"./media/03_1.jpg\"  # 替换为您的图片路径\n",
        "    result = recognize_location_from_image(image_path)\n",
        "    print(\"地点识别结果：\")\n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 一、实现图片理解\n",
        "初始化配置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 环境依赖与客户端初始化\n",
        "# - 需要 openai>=1.30.0 （API 兼容 StepFun）\n",
        "# - 需要设置环境变量 API_KEY\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "STEPFUN_API_KEY = os.environ.get(\"STEPFUN_API_KEY\")\n",
        "if not STEPFUN_API_KEY:\n",
        "    raise RuntimeError(\"未检测到环境变量 API_KEY，请在运行前设置，例如：export API_KEY='sk-xxx'\")\n",
        "\n",
        "# 指向 StepFun 平台\n",
        "client = OpenAI(api_key=STEPFUN_API_KEY, base_url=\"https://api.stepfun.com/v1\")\n",
        "\n",
        "DEFAULT_VISION_MODEL = \"step-1o-turbo-vision\"\n",
        "\n",
        "system_prompt = \"你是由阶跃星辰提供的AI聊天助手，你除了擅长中文，英文，以及多种其他语言的对话以外，还能够根据用户提供的图片，对内容进行精准的内容文本描述。在保证用户数据安全的前提下，你能对用户的问题和请求，作出快速和精准的回答。同时，你的回答和建议应该拒绝黄赌毒，暴力恐怖主义的内容\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  1.1简单图片理解"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "traceid: 30279ed3ae7edd5ace0045e707145dd4\n",
            "这张图片中，女士身着一袭黑色抹胸礼服，礼服设计简约而优雅，突显出端庄的气质。她的长发自然垂落，微微卷曲，发丝柔顺地披在肩头，散发出一种温婉的美感。她佩戴着精致的珠宝，耳畔是华丽的长款耳环，闪烁着璀璨的光芒，与颈间的钻石项链相得益彰，更添几分高贵与典雅。她的姿态从容，手指上也点缀着一枚戒指，整体造型完美融合了优雅与时尚。背景色调温暖，衬托出她的气质如兰，宛如一幅精心雕琢的艺术作品。\n"
          ]
        }
      ],
      "source": [
        "# 简单图片理解示例\n",
        "# 传入一张图片并请求描述\n",
        "# 阶跃星辰支持在 image_url 类型中使用 URL 或 Base64 格式的内容，为了保证更好的性能，推荐使用 URL 来完成图片参数的传递\n",
        "\n",
        "TEST_IMAGE_URL = \"https://q0.itc.cn/q_70/images01/20240612/8e0b7aecb4984be19faaa78f4ecd7c92.jpeg\"\n",
        "completion = client.chat.completions.create(\n",
        "    model=DEFAULT_VISION_MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"用优雅的语言描述这张图片\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": TEST_IMAGE_URL},\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "print(\"traceid:\",completion.id.split('.', 1)[0])\n",
        "print(completion.choices[0].message.content)\n",
        "#用优雅的语言描述这张图片"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 基于图片的多轮对话"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "第一次回答： 这张图片展现了一幅令人心醉的巴黎风光。画面中央是雄伟的**埃菲尔铁塔**，铁塔在阳光的照耀下泛着温暖的金色光芒，结构精致而宏伟，彰显出工业革命时期的建筑美学。铁塔上方悬挂着**奥运五环标志**，象征着巴黎即将举办的2024年奥运会，为这座历史建筑增添了一抹现代体育精神的色彩。\n",
            "\n",
            "铁塔的背景是一片壮丽的**双层彩虹**，横跨天际，从画面的左下角延伸至右上角，色彩斑斓，与灰蓝色的天空形成鲜明对比。彩虹的出现为整个场景增添了一种梦幻与希望的氛围，仿佛是大自然为这座浪漫城市特意绘制的礼物。\n",
            "\n",
            "在铁塔前方是**塞纳河**，河水波光粼粼，两艘白色游船静静地停泊在河面上，船上写有“Vedettes du Pont de l’Alma”字样，为画面增添了生活气息。河岸两侧绿树成荫，与铁塔和彩虹共同构成了一幅和谐的自然与人文景观。\n",
            "\n",
            "整个画面在阳光与彩虹的映衬下，充满了浪漫、活力与希望，完美地展现了巴黎作为“光之城”与“浪漫之都”的魅力，同时也预示着巴黎2024年奥运会的辉煌与多彩。\n",
            "\n",
            "这不仅是一幅风景图，更像是一封写给巴黎的情书，诉说着这座城市的永恒魅力与无限活力。\n",
            "第二次回答： 这张照片拍摄的是**法国巴黎的埃菲尔铁塔**，背景是著名的**塞纳河**，以及天空中壮丽的**双层彩虹**。画面中埃菲尔铁塔上悬挂的**奥运五环标志**表明，这可能是为**2024年巴黎奥运会**所做的特别装饰，预示着巴黎正在为这场全球体育盛会做准备。\n",
            "\n",
            "### 具体地点分析：\n",
            "1. **埃菲尔铁塔（Eiffel Tower）**：\n",
            "   - 位于巴黎战神广场（Champ de Mars），是巴黎的标志性建筑，也是法国的象征之一。\n",
            "   - 铁塔建于1889年，为纪念法国大革命100周年及巴黎世博会而建造，如今已成为全球最受欢迎的旅游景点之一。\n",
            "\n",
            "2. **塞纳河（Seine River）**：\n",
            "   - 照片前景是塞纳河，河上停泊着游船，这些游船通常用于游客观光，沿着塞纳河欣赏巴黎的美景。\n",
            "   - 塞纳河贯穿巴黎市中心，两岸分布着许多历史建筑与景点。\n",
            "\n",
            "3. **奥运五环标志**：\n",
            "   - 埃菲尔铁塔上悬挂的五环标志表明，巴黎正在为**2024年夏季奥运会**做准备。这一细节突显了巴黎作为奥运会主办城市的特殊时刻。\n",
            "\n",
            "4. **彩虹**：\n",
            "   - 天空中出现了**双层彩虹**，这是一种自然现象，为画面增添了梦幻的色彩，也使得这张照片更加独特和美丽。\n",
            "\n",
            "### 总结：\n",
            "这张照片拍摄于**法国巴黎的埃菲尔铁塔及其周边区域**，具体地点可能是从塞纳河对岸或河畔某个位置拍摄的。画面不仅展示了巴黎的经典地标，还融入了2024年奥运会的元素，是一幅充满浪漫与现代活力的图像。\n",
            "\n",
            "### 可能的拍摄位置：\n",
            "摄影师可能站在**塞纳河左岸**，面向埃菲尔铁塔拍摄，位置大概在**耶拿桥（Pont de l'Alma）**附近，因为游船上有“Vedettes du Pont de l’Alma”的标志，表明这里与耶拿桥相关。耶拿桥是巴黎著名的桥梁之一，靠近埃菲尔铁塔，是观赏铁塔的绝佳地点之一。\n",
            "\n",
            "### 场景意义：\n",
            "这张照片不仅记录了巴黎的美丽风光，还象征着巴黎作为浪漫之都与奥运主办城市的双重身份，展现了历史与现代、自然与人文的完美融合。\n"
          ]
        }
      ],
      "source": [
        "TEST_IMAGE_URL = \"https://img.meituan.net/leadinimg/fb9411ee59deb2330085f6979aa4a847149136.webp%40watermark%3D0\"\n",
        "\n",
        "messages = []\n",
        "\n",
        "messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "\n",
        "# 第一轮：带图提问\n",
        "messages.append({\n",
        "    \"role\": \"user\",\n",
        "    \"content\": [\n",
        "        {\"type\": \"text\", \"text\": \"用优雅的语言描述这张图片\"},\n",
        "        {\"type\": \"image_url\", \"image_url\": {\"url\": TEST_IMAGE_URL}}\n",
        "    ]\n",
        "})\n",
        "\n",
        "# 调一次模型，生成第一轮描述\n",
        "resp1 = client.chat.completions.create(\n",
        "    model=DEFAULT_VISION_MODEL,\n",
        "    messages=messages\n",
        ")\n",
        "first_answer = resp1.choices[0].message.content\n",
        "print( \"第一次回答：\",first_answer)\n",
        "# 把模型回答放入上下文，成为对话历史\n",
        "messages.append({\"role\": \"assistant\", \"content\": first_answer})\n",
        "\n",
        "# 第二轮：用户继续追问\n",
        "messages.append({\"role\": \"user\", \"content\": \"这张照片中是什么地方？\"})\n",
        "\n",
        "# 再调一次模型，进行多轮对话\n",
        "resp2 = client.chat.completions.create(\n",
        "    model=DEFAULT_VISION_MODEL,\n",
        "    messages=messages\n",
        ")\n",
        "second_answer = resp2.choices[0].message.content\n",
        "\n",
        "print( \"第二次回答：\",second_answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 设置detail参数为low和high"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- step-1v 默认会选择低分辨率，每张图片 400 token\n",
        "- step-1o 系列模型低分辨率情况下，默认每张图片 169 token；当 detail 模式为 high 时，图片的 Token 消耗将会基于图片大小进行计算"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "low detail模式: 图中 **五常大米** 的价格是 **15元**。  \n",
            "\\boxed{15元} ...\n",
            "\n",
            "\n",
            "high detail模式: 图中五常大米的价格是 **5/份**。  \n",
            "\\boxed{5/份} ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 菜单图例\n",
        "TEST_IMAGE_URL = \"https://p0.meituan.net/biztone/7479e268c42b856cbe6dd09969a31b9e2131519.jpg%40watermark%3D0\"\n",
        "\n",
        "def describe_image(img_url: str, detail: str = \"high\") -> str:\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"识别图中五常大米的价格\"}, #5元一份\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": img_url, \"detail\": detail}},\n",
        "            ],\n",
        "        },\n",
        "    ]\n",
        "    completion = client.chat.completions.create(model=DEFAULT_VISION_MODEL, messages=messages,temperature= 0)\n",
        "    # print(\"traceid:\",completion.id.split('.', 1)[0])\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "image_desc_low = describe_image(TEST_IMAGE_URL, detail=\"low\")\n",
        "print(\"\\nlow detail模式:\",image_desc_low,\"...\\n\")\n",
        "image_desc_high = describe_image(TEST_IMAGE_URL, detail=\"high\")\n",
        "print(\"\\nhigh detail模式:\",image_desc_high, \"...\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 多图图片理解\n",
        "\n",
        "根据模型不同，一次多轮对话最多可以拥有不超过 10 张照片或 50 张照片\n",
        "当图片数量可能超过上限（当前单次请求上限为 60 张）时，可先用模型为每张图生成描述，然后将描述作为对话上下文，继续进行真正的问答。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "   \"id\": \"84675650f205d830b148431680898a5d.858cf0596e90686c28e2b955694b46ed\",\n",
            "   \"choices\": [\n",
            "      {\n",
            "         \"finish_reason\": \"stop\",\n",
            "         \"index\": 0,\n",
            "         \"logprobs\": null,\n",
            "         \"message\": {\n",
            "            \"content\": \"这几张图片里出现了 **3个不同的女生**。  \\n\\n### 判断依据：\\n1. **前四张图片（1-4）** 中的女生是同一个人，因为她在外貌、发型和整体气质上一致，尤其是面部轮廓、五官和黑长直的头发特征相似。  \\n   - 第1张：黑色礼服，佩戴华丽的耳环和项链。  \\n   - 第2张：浅绿色礼服，发型为低盘发，佩戴珍珠耳环。  \\n   - 第3张：银色亮片礼服，外搭黑白毛绒外套，项链为金属质感。  \\n   - 第4张：深蓝色礼服，搭配浅蓝色薄纱，长卷发披肩。  \\n\\n   这四张图片应为 **同一个女生**，因为她无论在妆容、五官还是整体气质上都非常一致。  \\n\\n2. **第5张和第6张图片** 中的女生是 **同一个人**，因为：  \\n   - 第5张：她穿着白色衣服，耳朵上戴着金色耳环，表情冷艳，手托下巴，黑长直的发型。  \\n   - 第6张：她穿着红色吊带衣服，手里拿着一个装有水的玻璃瓶，表情温柔，头发为深棕色且披散下来。  \\n   这两张图片中的女生在外貌、面部特征（如泪痣位置）和整体气质上一致，应为 **同一个人**。  \\n\\n3. **第7张图片** 中的女生是 **另一个人**，因为她的面部轮廓、五官结构与前两个女生明显不同。她的头发为卷发，妆容更加温柔，且礼服设计与之前的不同，整体感觉更柔和，因此是 **第三个不同的女生**。  \\n\\n### 结论：\\n图片中一共出现了 **3个不同的女生**。  \\n- 前四张（1-4）是 **第1个女生**。  \\n- 第5张和第6张是 **第2个女生**。  \\n- 第7张是 **第3个女生**。\",\n",
            "            \"refusal\": null,\n",
            "            \"role\": \"assistant\",\n",
            "            \"annotations\": null,\n",
            "            \"audio\": null,\n",
            "            \"function_call\": null,\n",
            "            \"tool_calls\": null\n",
            "         }\n",
            "      }\n",
            "   ],\n",
            "   \"created\": 1762849751,\n",
            "   \"model\": \"step-1o-turbo-vision\",\n",
            "   \"object\": \"chat.completion\",\n",
            "   \"service_tier\": null,\n",
            "   \"system_fingerprint\": null,\n",
            "   \"usage\": {\n",
            "      \"completion_tokens\": 439,\n",
            "      \"prompt_tokens\": 1300,\n",
            "      \"total_tokens\": 1739,\n",
            "      \"completion_tokens_details\": null,\n",
            "      \"prompt_tokens_details\": null\n",
            "   }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# 多图理解来识别有几位不同人物\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"step-1o-turbo-vision\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"这几张图片里出现了几个不同的女生\", #3个\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"https://q0.itc.cn/q_70/images01/20240612/8e0b7aecb4984be19faaa78f4ecd7c92.jpeg\" #杨幂\n",
        "                    },\n",
        "                },\n",
        "                {\n",
        "                    \"type\":\"image_url\",\n",
        "                    \"image_url\":{\n",
        "                        \"url\":\"https://gd-hbimg.huaban.com/2b4d0f9fc1515d4d1d2d498b8318dbac3491cc58175ee-83PEcb_fw1200webp\"#杨幂\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"type\":\"image_url\",\n",
        "                    \"image_url\":{\n",
        "                        \"url\":\"https://gd-hbimg.huaban.com/30576c5c513d28154df3cee1570027bb95a47bc0413d4-6sNdZc_fw1200webp\"#杨幂\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"type\":\"image_url\",\n",
        "                    \"image_url\":{\n",
        "                        \"url\":\"https://gd-hbimg.huaban.com/14eb4eb2e87b9a46973e9ddca872750043375ad02818c-ildFmT_fw1200webp\"#杨幂\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"https://img0.baidu.com/it/u=3612072719,173171671&fm=253&app=138&f=JPEG?w=800&h=1067\" #李一桐\n",
        "                    },\n",
        "                },\n",
        "                                {\n",
        "                    \"type\":\"image_url\",\n",
        "                    \"image_url\":{\n",
        "                        \"url\":\"https://q6.itc.cn/q_70/images03/20250803/36c739326f074529a145f650f21966a7.jpeg\" #李一桐\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"type\":\"image_url\",\n",
        "                    \"image_url\":{\n",
        "                        \"url\":\"https://pics3.baidu.com/feed/bf096b63f6246b6003c2629632906143530fa2f8.jpeg@f_auto?token=c549b4f7593f2ecff51c6c1e7fd67201\" #白鹿\n",
        "                    }\n",
        "                }\n",
        "            ],\n",
        "        },\n",
        "    ],\n",
        ")\n",
        " \n",
        "print(completion.model_dump_json(indent=3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.5 使用 Base64 编码来传递图片内容\n",
        "![image.png](https://platform.stepfun.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbase64image.f0a0bc95.jpg&w=3840&q=75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "731b5f25ed38e3b392defb022b0e7bd3.0516e8f7d7d47949ed6f54d514c91622\n",
            "这道菜是**鱼香肉丝**，一道经典的川菜，以其咸、甜、酸、辣、香的复合味道而闻名，虽然名字中有“鱼香”，但其实并不含有鱼，而是用调味料模仿出鱼的香味。以下是这道菜的详细做法和所需食材：\n",
            "\n",
            "---\n",
            "\n",
            "### **所需食材：**\n",
            "#### 主料：\n",
            "- 猪里脊肉：200 克  \n",
            "#### 配菜：\n",
            "- 胡萝卜：1 根（中等大小，约 50 克，切丝）  \n",
            "- 青椒：1 个（约 50 克，切丝）  \n",
            "- 木耳：10 克（干木耳，提前泡发，切丝）  \n",
            "- �香菇：2 朵（可选，切片或切丝）  \n",
            "#### 调料：\n",
            "- **腌肉调料**：\n",
            "  - 生抽：1 茶匙  \n",
            "  - 料酒：1 茶匙  \n",
            "  - 淀粉：1 茶匙  \n",
            "  - 食用油：半茶匙  \n",
            "  - 盐：少许  \n",
            "- **鱼香汁**：\n",
            "  - 生抽：1 汤匙  \n",
            "  - 陈醋：2 汤匙  \n",
            "  - 白糖：1.5 汤匙  \n",
            "  - 料酒：1 茶匙  \n",
            "  - 淀粉：1 茶匙  \n",
            "  - 清水：3 汤匙  \n",
            "  - 豆瓣酱：1 茶匙（可选，增加辣味和红油）  \n",
            "- **其他调料**：\n",
            "  - 蒜末：适量（约 2-3 瓣）  \n",
            "  - 姜末：适量（约 1 小块）  \n",
            "  - 葱花：适量  \n",
            "  - 红泡椒（或剁椒）：1-2 汤匙（增加辣味和传统鱼香风味，可选）  \n",
            "  - 食用油：适量  \n",
            "\n",
            "---\n",
            "\n",
            "### **详细做法：**\n",
            "\n",
            "#### **1. 食材准备：**\n",
            "   - **猪肉处理**：猪里脊肉切成细丝，放入碗中，加入 **1 茶匙生抽**、**1 茶匙料酒**、**1 茶匙淀粉** 和 **少许盐**，抓匀后加入 **半茶匙食用油**，再次抓匀，腌制 10 分钟，让肉丝更嫩。  \n",
            "   - **配菜处理**：胡萝卜、青椒、木耳、香菇分别洗净，切成细丝备用。如果使用干木耳，需提前用温水泡发，去蒂后切丝。  \n",
            "   - **鱼香汁调制**：取一个小碗，加入 **1 汤匙生抽**、**2 汤匙陈醋**、**1.5 汤匙白糖**、**1 茶匙料酒**、**1 茶匙淀粉** 和 **3 汤匙清水**，搅拌均匀备用。这一步很关键，鱼香汁的比例决定了味道是否正宗。  \n",
            "\n",
            "#### **2. 炒制过程：**\n",
            "   - **炒肉丝**：锅中倒入适量油，油热后（约 6 成热），放入腌好的肉丝，快速滑炒至肉丝变白、散开，盛出备用。  \n",
            "   - **炒配菜**：锅中留底油，放入 **姜末**、**蒜末** 和 **葱花** 爆香。如果使用红泡椒或豆瓣酱，此时可以加入 **1-2 汤匙红泡椒（或 1 茶匙豆瓣酱）**，炒出红油和香味。  \n",
            "   - 加入胡萝卜丝、青椒丝、木耳丝和香菇丝，大火翻炒均匀，炒至配菜断生（约 1-2 分钟）。  \n",
            "   - 将炒好的肉丝重新倒入锅中，与配菜翻炒均匀。  \n",
            "\n",
            "#### **3. 调味收汁：**\n",
            "   - 倒入调好的 **鱼香汁**，快速翻炒均匀，让汤汁包裹住所有食材。  \n",
            "   - 继续翻炒约 30 秒到 1 分钟，直到汤汁变浓稠，所有食材都均匀裹上酱汁，关火。  \n",
            "\n",
            "#### **4. 出锅装盘：**\n",
            "   - 将炒好的鱼香肉丝盛出装盘，即可享用。  \n",
            "\n",
            "---\n",
            "\n",
            "### **小贴士：**\n",
            "1. **鱼香汁的比例**：鱼香肉丝的灵魂在于鱼香汁，其中 **醋 : 糖 : 生抽 = 2 : 1.5 : 1** 是经典比例，可以根据个人口味稍作调整。喜欢酸甜口的可以多加一点糖或醋。  \n",
            "2. **肉丝嫩滑的秘诀**：腌肉时加入淀粉和油，可以锁住肉丝的水分，炒出来的肉丝更加滑嫩。  \n",
            "3. **红泡椒的作用**：传统的鱼香肉丝会用红泡椒来增加辣味和特有的酸香味，如果家里没有，可以用豆瓣酱或剁椒代替，但风味会稍有不同。  \n",
            "4. **配菜选择**：鱼香肉丝的配菜可以灵活调整，除了胡萝卜、青椒、木耳，还可以加入竹笋丝或莴笋丝，风味更佳。  \n",
            "\n",
            "---\n",
            "\n",
            "这道菜色香味俱全，非常下饭，适合搭配白米饭一起食用！\n"
          ]
        }
      ],
      "source": [
        "# 以 Base64 输入图片\n",
        "import base64\n",
        "with open(\"./media/01_鱼香肉丝.jpg\", \"rb\") as image_file:\n",
        "    base64_bytes = base64.b64encode(image_file.read())\n",
        "    base64_bytes = base64_bytes.decode('utf-8')\n",
        "\n",
        "user_prompt=\"\"\"\n",
        "请识别这张图片中的菜名，并给出这道菜的详细做法和所需食材。\n",
        "\"\"\"\n",
        "\n",
        "completion_b64 = client.chat.completions.create(\n",
        "    model=DEFAULT_VISION_MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": user_prompt},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/png;base64,{base64_bytes}\",\n",
        "                        \"detail\": \"high\",\n",
        "                    },\n",
        "\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(completion_b64.id)\n",
        "print(completion_b64.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 二、常见问题处理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 图片预处理以降低延迟\n",
        "预处理：对图片缩放与压缩来获得较好的处理速度\n",
        "- step-1o 对于 detail=low 或默认，可将最长边缩放至 728px\n",
        "- step-1o 对于 detail=high，可将最长边缩放至 504 的倍数 （示例调整为1008）\n",
        "- step-1v 对于 detail=low 或默认，可将最长边缩放至 1280px\n",
        "- step-1v 对于 detail=high，可将最长边缩放至 2688px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "图片已调整尺寸 (max size: 1008)。\n",
            "PNG 已有损转换为 JPEG (Quality: 80)。\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from PIL import Image\n",
        "# 确保安装了Pillow库\n",
        "# 运行以下命令以安装Pillow\n",
        "# pip install Pillow\n",
        " \n",
        " \n",
        "# 适用于jpg，压缩图片质量，quality 值通常在 1 到 95 之间，80 是一个常用的平衡点\n",
        "def compress(input_path, output_path, quality):\n",
        "    image = Image.open(input_path)\n",
        "    image.save(output_path, quality=quality,optimize=True)\n",
        "    print(f\"图片已压缩 (Quality: {quality})。\")\n",
        "\n",
        "\n",
        "# 适用于png,转为jpg后压缩图片质量\n",
        "def compress_png(file_path,output_path, quality):\n",
        "    image = Image.open(file_path)\n",
        "    # 注意：如果 PNG 带有透明度，需要先转换为 RGB 模式，否则会报错或产生黑色背景\n",
        "    if image.mode in ('RGBA', 'P'):\n",
        "        image = image.convert('RGB')\n",
        "    image.save(output_path, 'JPEG', quality=quality, optimize=True)\n",
        "    print(f\"PNG 已有损转换为 JPEG (Quality: {quality})。\")\n",
        "\n",
        "# 将图片按照最长边resize，短边等比例缩放，并存储为新图片\n",
        "def resize_image(input_path, output_path, max_size):\n",
        "    image = Image.open(input_path)\n",
        "    width, height = image.size\n",
        " \n",
        "    # 计算新的尺寸\n",
        "    if width > height:\n",
        "        new_width = max_size\n",
        "        new_height = int((max_size / width) * height)\n",
        "    else:\n",
        "        new_height = max_size\n",
        "        new_width = int((max_size / height) * width)\n",
        " \n",
        "    # 调整图片尺寸\n",
        "    resized_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "    resized_image.save(output_path)\n",
        "    print(f\"图片已调整尺寸 (max size: {max_size})。\")\n",
        " \n",
        "# 调用函数\n",
        "resize_image('./media/03_doraemon.png', './media/03_doraemon_resized.png', 1008)\n",
        "compress_png('./media/03_doraemon.png', './media/03_doraemon_requality.jpg', 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 透明背景图片\n",
        "目前 step-1o 系列的模型支持对透明背景的 PNG 图片进行处理，但在使用时，会将透明通道处理景为黑色的情况。你可以通过对图片进行处理，将其背景设置为白色，从而避免模型在推理时，无法正确理解图片中的内容。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 透明 PNG 适配：RGBA 转 RGB 白色背景\n",
        "# https://gd-hbimg.huaban.com/7c4795bc026c359c8d17ff19d1d25b574fbb43e03088e9-ena8d7_fw1200webp\n",
        "from PIL import Image\n",
        "\n",
        "def convert_rgba_to_rgb_with_white_background(input_path: str, output_path: str) -> None:\n",
        "    img = Image.open(input_path)\n",
        "    if img.mode != \"RGBA\":\n",
        "        raise ValueError(\"输入图片不是 RGBA 模式\")\n",
        "    white_background = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
        "    white_background.paste(img, mask=img.split()[3])\n",
        "    result = white_background.convert(\"RGB\")\n",
        "    result.save(output_path)\n",
        "\n",
        "convert_rgba_to_rgb_with_white_background(\"./media/03_rgba.webp\", \"./media/03_rgb.webp\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 三、其他应用"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 识别图中的单个主体并图片标注"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "图像大小: (1200, 2596)\n",
            "系统提示内容:\n",
            "\n",
            " 你是一个专业的图像分析助手。你的任务是：根据用户的自然语言描述，在给定图片中定位需要裁剪的**核心主体**区域，并仅输出一个裁剪框。\n",
            "\n",
            "【输出格式（必须严格遵守）】\n",
            "只输出一个 JSON 对象，不要包含任何其他解释或文字：\n",
            "{\n",
            "  \"top_left\": [x1, y1],\n",
            "  \"bottom_right\": [x2, y2],\n",
            "  \"confidence\": 0.95\n",
            "}\n",
            "\n",
            "【坐标与边界规则】\n",
            "1) 使用**相对坐标制**：范围 0~1000 的整数；(0,0) 为左上角，x 向右、y 向下。\n",
            "2) 所有坐标必须位于图像范围内，且满足 x1 < x2、y1 < y2。\n",
            "3) 你的输出只有**一个**裁剪框；如存在多个可能主体，应将它们**合并为一个更大框**以避免重叠问题。\n",
            "4) 框需要**完整包含**用户描述的主体，同时**适度保留上下文**，避免过紧贴边缘。\n",
            "5) 置信度 confidence 取值 0.0–1.0，代表你对本次定位准确度的判断。\n",
            "\n",
            "【一致性要求】\n",
            "- 坐标字段名固定为 \"top_left\" 与 \"bottom_right\"；值均为两个整数 [x, y]，范围 0–1000。\n",
            "- 输出中不得包含额外字段、注释或解释。\n",
            "\n",
            "ChatCompletion(id='c04b4b8539925c55b40cbfd1b4c2de9c.f5ef13d830b0730a79e3d1601ad9b806', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"top_left\": [150, 150], \"bottom_right\": [850, 950], \"confidence\": 0.95}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1762851751, model='step-1o-vision-32k', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=44, prompt_tokens=1809, total_tokens=1853, completion_tokens_details=None, prompt_tokens_details=None, cached_tokens=256))\n",
            "原始返回： {\"top_left\": [150, 150], \"bottom_right\": [850, 950], \"confidence\": 0.95}\n",
            "标注后的图像已保存至 ./media/03_rgb_annotated.png\n",
            "{\"top_left\": [150, 150], \"bottom_right\": [850, 950], \"confidence\": 0.95}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import base64\n",
        "import json\n",
        "import time\n",
        "from typing import Dict, Any, Tuple, Optional, List\n",
        "\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from openai import OpenAI\n",
        "\n",
        "STEP_API_KEY = os.environ[\"STEPFUN_API_KEY\"]\n",
        "BASE_URL=\"https://api.stepfun.com/v1\"\n",
        "\n",
        "MODEL_NAME = \"step-1o-vision-32k\"\n",
        "RESPONSE_FORMAT_JSON = {\"type\": \"json_object\"}\n",
        "\n",
        "# 坐标模式（用于可视化落地到像素）：强制相对坐标（0~1000）\n",
        "POSITION_MODE = \"relative_0_1000\"\n",
        "\n",
        "# 输入/输出\n",
        "INPUT_IMAGE_PATH = \"./media/03_rgb.webp\"\n",
        "OUTPUT_IMAGE_DIR = \"./media\"     # 目录；程序会自动生成文件名\n",
        "DRAW_LABEL = \"crop\"                         # 在图上绘制的框标签\n",
        "FONT_PATHS = [\n",
        "    \"/System/Library/Fonts/Supplemental/Arial Unicode.ttf\",\n",
        "    \"/System/Library/Fonts/Helvetica.ttc\",\n",
        "    \"arial.ttf\",\n",
        "]\n",
        "FONT_SIZE = 20\n",
        "\n",
        "# 用户自然语言主体描述（示例：请按需修改）\n",
        "SUBJECT_DESCRIPTION = \"识别图中主体，完整包含并保留少量上下文边缘空间\"\n",
        "\n",
        "# 重试\n",
        "MAX_RETRIES = 5\n",
        "RETRY_SLEEP_SECONDS = 1\n",
        "\n",
        "# 调试输出\n",
        "VERBOSE = True\n",
        "# ===== 配置区域结束 ======\n",
        "\n",
        "client = OpenAI(api_key=STEP_API_KEY, base_url=BASE_URL)\n",
        "\n",
        "\n",
        "def log(*args):\n",
        "    if VERBOSE:\n",
        "        print(*args)\n",
        "\n",
        "# ====== 提示词 =========\n",
        "def build_system_prompt() -> str:\n",
        "    \"\"\"\n",
        "    严格约束输出为单一裁剪框的 JSON：\n",
        "    {\n",
        "      \"top_left\": [x1, y1],\n",
        "      \"bottom_right\": [x2, y2],\n",
        "      \"confidence\": 0.95\n",
        "    }\n",
        "    \"\"\"\n",
        "    return (\n",
        "        \"你是一个专业的图像分析助手。你的任务是：根据用户的自然语言描述，\"\n",
        "        \"在给定图片中定位需要裁剪的**核心主体**区域，并仅输出一个裁剪框。\\n\\n\"\n",
        "        \"【输出格式（必须严格遵守）】\\n\"\n",
        "        \"只输出一个 JSON 对象，不要包含任何其他解释或文字：\\n\"\n",
        "        \"{\\n\"\n",
        "        \"  \\\"top_left\\\": [x1, y1],\\n\"\n",
        "        \"  \\\"bottom_right\\\": [x2, y2],\\n\"\n",
        "        \"  \\\"confidence\\\": 0.95\\n\"\n",
        "        \"}\\n\\n\"\n",
        "        \"【坐标与边界规则】\\n\"\n",
        "        \"1) 使用**相对坐标制**：范围 0~1000 的整数；(0,0) 为左上角，x 向右、y 向下。\\n\"\n",
        "        \"2) 所有坐标必须位于图像范围内，且满足 x1 < x2、y1 < y2。\\n\"\n",
        "        \"3) 你的输出只有**一个**裁剪框；如存在多个可能主体，应将它们**合并为一个更大框**以避免重叠问题。\\n\"\n",
        "        \"4) 框需要**完整包含**用户描述的主体，同时**适度保留上下文**，避免过紧贴边缘。\\n\"\n",
        "        \"5) 置信度 confidence 取值 0.0–1.0，代表你对本次定位准确度的判断。\\n\\n\"\n",
        "        \"【一致性要求】\\n\"\n",
        "        \"- 坐标字段名固定为 \\\"top_left\\\" 与 \\\"bottom_right\\\"；值均为两个整数 [x, y]，范围 0–1000。\\n\"\n",
        "        \"- 输出中不得包含额外字段、注释或解释。\\n\"\n",
        "    )\n",
        "\n",
        "\n",
        "# ====== 工具函数 =========\n",
        "def get_image_size(image_path: str) -> Tuple[int, int]:\n",
        "    with Image.open(image_path) as img:\n",
        "        return img.size  # (w, h)\n",
        "\n",
        "\n",
        "def image_to_base64(image_path: str) -> str:\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "\n",
        "def _clamp(v: int, low: int, high: int) -> int:\n",
        "    return max(low, min(v, high))\n",
        "\n",
        "\n",
        "def _to_int2(pt: List[Any]) -> Optional[Tuple[int, int]]:\n",
        "    if not isinstance(pt, (list, tuple)) or len(pt) != 2:\n",
        "        return None\n",
        "    try:\n",
        "        x = int(round(float(pt[0])))\n",
        "        y = int(round(float(pt[1])))\n",
        "        return x, y\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def validate_relative_bbox(bbox: Dict[str, Any]) -> bool:\n",
        "    \"\"\"\n",
        "    校验相对坐标 0..1000，x1<x2, y1<y2\n",
        "    \"\"\"\n",
        "    tl = _to_int2(bbox.get(\"top_left\"))\n",
        "    br = _to_int2(bbox.get(\"bottom_right\"))\n",
        "    if tl is None or br is None:\n",
        "        return False\n",
        "    x1, y1 = tl\n",
        "    x2, y2 = br\n",
        "    if not (0 <= x1 < x2 <= 1000 and 0 <= y1 < y2 <= 1000):\n",
        "        return False\n",
        "    conf = bbox.get(\"confidence\")\n",
        "    try:\n",
        "        conf = float(conf)\n",
        "    except Exception:\n",
        "        return False\n",
        "    return 0.0 <= conf <= 1.0\n",
        "\n",
        "\n",
        "def rel_to_abs_bbox(bbox: Dict[str, Any], img_size: Tuple[int, int]) -> Tuple[int, int, int, int]:\n",
        "    \"\"\"\n",
        "    将相对 0..1000 的坐标转换为像素坐标（用于可视化）\n",
        "    \"\"\"\n",
        "    w, h = img_size\n",
        "    x1_rel, y1_rel = bbox[\"top_left\"]\n",
        "    x2_rel, y2_rel = bbox[\"bottom_right\"]\n",
        "    x1 = int(round(x1_rel / 1000.0 * w))\n",
        "    y1 = int(round(y1_rel / 1000.0 * h))\n",
        "    x2 = int(round(x2_rel / 1000.0 * w))\n",
        "    y2 = int(round(y2_rel / 1000.0 * h))\n",
        "    # 夹取并保证有效\n",
        "    x1 = _clamp(x1, 0, w - 2)\n",
        "    y1 = _clamp(y1, 0, h - 2)\n",
        "    x2 = _clamp(max(x2, x1 + 1), 1, w - 1)\n",
        "    y2 = _clamp(max(y2, y1 + 1), 1, h - 1)\n",
        "    return x1, y1, x2, y2\n",
        "\n",
        "\n",
        "def _load_font(paths: List[str], size: int) -> ImageFont.FreeTypeFont:\n",
        "    for p in paths:\n",
        "        try:\n",
        "            return ImageFont.truetype(p, size=size)\n",
        "        except Exception:\n",
        "            continue\n",
        "    return ImageFont.load_default()\n",
        "\n",
        "\n",
        "def annotate_image(image_path: str, bbox_abs: Tuple[int, int, int, int], output_path: str, label: str = \"crop\") -> None:\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    with Image.open(image_path) as img:\n",
        "        if img.mode != \"RGBA\":\n",
        "            img = img.convert(\"RGBA\")\n",
        "\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        font = _load_font(FONT_PATHS, FONT_SIZE)\n",
        "\n",
        "        x1, y1, x2, y2 = bbox_abs\n",
        "        draw.rectangle([x1, y1, x2, y2], outline=(255, 0, 0, 255), width=2)\n",
        "\n",
        "        # 居中标签\n",
        "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "        l, t, r, b = draw.textbbox((0, 0), label, font=font)\n",
        "        tw, th = r - l, b - t\n",
        "        pad = 6\n",
        "        rect = [cx - tw // 2 - pad, cy - th // 2 - pad, cx + tw // 2 + pad, cy + th // 2 + pad]\n",
        "        W, H = img.size\n",
        "        # 夹取\n",
        "        dx = -min(0, rect[0]) + min(0, W - rect[2])\n",
        "        dy = -min(0, rect[1]) + min(0, H - rect[3])\n",
        "        rect = [rect[0] + dx, rect[1] + dy, rect[2] + dx, rect[3] + dy]\n",
        "\n",
        "        draw.rectangle(rect, fill=(0, 0, 0, 140))\n",
        "        draw.text((rect[0] + pad, rect[1] + pad), label, fill=(255, 255, 255, 255), font=font)\n",
        "\n",
        "        ext = os.path.splitext(output_path)[1].lower()\n",
        "        if ext in [\".jpg\", \".jpeg\"]:\n",
        "            background = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
        "            background.paste(img, mask=img.split()[3])\n",
        "            background.save(output_path, quality=95)\n",
        "        else:\n",
        "            img.save(output_path)\n",
        "\n",
        "    log(f\"标注后的图像已保存至 {output_path}\")\n",
        "\n",
        "\n",
        "# ====== 推理请求 =========\n",
        "def call_model(image_b64: str, description: str) -> Optional[Dict[str, Any]]:\n",
        "    sys_prompt = build_system_prompt()\n",
        "    log(\"系统提示内容:\\n\\n\", sys_prompt)\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": sys_prompt},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": f\"主体描述：{description}\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpg;base64,{image_b64}\",\n",
        "                        \"detail\": \"high\",\n",
        "                    },\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": \"请基于以上描述与图像，返回唯一的裁剪框 JSON。\"},\n",
        "            ],\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            messages=messages,\n",
        "            model=MODEL_NAME,\n",
        "            response_format=RESPONSE_FORMAT_JSON,\n",
        "        )\n",
        "    except Exception as e:\n",
        "        log(f\"API请求失败: {e}\")\n",
        "        return None\n",
        "\n",
        "    # 打印完整响应（可按需注释）\n",
        "    log(response)\n",
        "\n",
        "    try:\n",
        "        content = response.choices[0].message.content.strip()\n",
        "        log(\"原始返回：\", content)\n",
        "        data = json.loads(content)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        log(\"解析JSON失败，请检查API返回内容。报错：\", e)\n",
        "        return None\n",
        "\n",
        "# ========= 主流程 =========\n",
        "def main():\n",
        "    img_w, img_h = get_image_size(INPUT_IMAGE_PATH)\n",
        "    log(f\"图像大小: {(img_w, img_h)}\")\n",
        "\n",
        "    image_b64 = image_to_base64(INPUT_IMAGE_PATH)\n",
        "\n",
        "    attempt = 0\n",
        "    while attempt < MAX_RETRIES:\n",
        "        try:\n",
        "            result = call_model(image_b64, SUBJECT_DESCRIPTION)\n",
        "            if not result:\n",
        "                log(\"未能获取有效的分析结果。\")\n",
        "                attempt += 1\n",
        "                time.sleep(RETRY_SLEEP_SECONDS)\n",
        "                continue\n",
        "\n",
        "            # 校验相对坐标与结构\n",
        "            if not validate_relative_bbox(result):\n",
        "                log(\"返回的坐标不符合 0..1000 或结构不正确，重试...\")\n",
        "                attempt += 1\n",
        "                time.sleep(RETRY_SLEEP_SECONDS)\n",
        "                continue\n",
        "\n",
        "            # 相对 -> 像素（仅用于可视化）\n",
        "            x1, y1, x2, y2 = rel_to_abs_bbox(result, (img_w, img_h))\n",
        "\n",
        "            # 生成输出文件名\n",
        "            os.makedirs(OUTPUT_IMAGE_DIR, exist_ok=True)\n",
        "            base_name = os.path.splitext(os.path.basename(INPUT_IMAGE_PATH))[0]\n",
        "            file_name = f\"{base_name}_annotated.png\"\n",
        "            output_path = os.path.join(OUTPUT_IMAGE_DIR, file_name)\n",
        "\n",
        "            annotate_image(INPUT_IMAGE_PATH, (x1, y1, x2, y2), output_path, DRAW_LABEL)\n",
        "\n",
        "            # 控制台也打印一次标准 JSON，便于直接消费\n",
        "            # 注意：此处打印的就是“相对坐标 0..1000”的原始返回\n",
        "            print(json.dumps({\n",
        "                \"top_left\": [int(result[\"top_left\"][0]), int(result[\"top_left\"][1])],\n",
        "                \"bottom_right\": [int(result[\"bottom_right\"][0]), int(result[\"bottom_right\"][1])],\n",
        "                \"confidence\": float(result[\"confidence\"])\n",
        "            }, ensure_ascii=False))\n",
        "            return\n",
        "\n",
        "        except Exception as e:\n",
        "            log(f\"发生错误: {e}\")\n",
        "            attempt += 1\n",
        "            time.sleep(RETRY_SLEEP_SECONDS)\n",
        "\n",
        "    log(\"达到最大重试次数，操作失败。\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 识别图片中的多个物体并标注"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "图像大小: (2000, 2664)\n",
            "ChatCompletion(id='e34ba07123a62c86bf36e5b2d333ccd7.fc18784054785e66df59e81e04187877', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='[\"144,388,348,536\",\"212,236,504,450\",\"524,288,722,438\",\"670,370,910,527\",\"346,476,660,712\"]', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1762855480, model='step-1o-vision-32k', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=82, prompt_tokens=2607, total_tokens=2689, completion_tokens_details=None, prompt_tokens_details=None, cached_tokens=256))\n",
            "原始返回： [\"144,388,348,536\",\"212,236,504,450\",\"524,288,722,438\",\"670,370,910,527\",\"346,476,660,712\"]\n",
            "字体加载: <PIL.ImageFont.FreeTypeFont object at 0x110a22d50>\n",
            "['144,388,348,536', '212,236,504,450', '524,288,722,438', '670,370,910,527', '346,476,660,712']\n",
            "标注后的图像已保存至 ./media/03_doraemon_requality_annotated.png\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import base64\n",
        "import json\n",
        "import time\n",
        "from typing import Dict, Any, Tuple, Optional, List\n",
        "\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from openai import OpenAI\n",
        "\n",
        "STEP_API_KEY = os.environ[\"STEPFUN_API_KEY\"]\n",
        "BASE_URL=\"https://api.stepfun.com/v1\"\n",
        "\n",
        "MODEL_NAME = \"step-1o-vision-32k\"\n",
        "RESPONSE_FORMAT_JSON = {\"type\": \"json_object\"}\n",
        "\n",
        "# 坐标模式（用于可视化落地到像素）：强制相对坐标（0~1000）\n",
        "POSITION_MODE = \"relative_0_1000\"\n",
        "\n",
        "# 输入/输出\n",
        "INPUT_IMAGE_PATH = \"./media/03_doraemon_requality.jpg\"\n",
        "OUTPUT_IMAGE_PATH = \"./media/03_doraemon_requality_annotated.png\"  \n",
        "\n",
        "DRAW_LABEL = \"crop\"                         # 在图上绘制的框标签\n",
        "FONT_PATHS = [\n",
        "    \"/System/Library/Fonts/Supplemental/Arial Unicode.ttf\",\n",
        "    \"/System/Library/Fonts/Helvetica.ttc\",\n",
        "    \"arial.ttf\",\n",
        "]\n",
        "FONT_SIZE = 20\n",
        "\n",
        "# 用户自然语言主体描述（示例：请按需修改）\n",
        "SUBJECT_DESCRIPTION = \"识别图中的卡通角色面部，注意要完整包含并保留少量边缘空间\"\n",
        "\n",
        "# 调试输出\n",
        "VERBOSE = True\n",
        "\n",
        "\n",
        "client = OpenAI(api_key=STEP_API_KEY, base_url=BASE_URL)\n",
        "\n",
        "\n",
        "def log(*args):\n",
        "    if VERBOSE:\n",
        "        print(*args)\n",
        "\n",
        "\n",
        "# ===== 提示词（Prompt） ===\n",
        "def build_system_prompt() -> str:\n",
        " \n",
        "    return (\n",
        "        \"\"\"\n",
        "        你是专业图像分析助手，需精准分析用户提供的图片，根据其描述识别所有指定主体区域，为每个主体输出准确包含主体的边界框坐标。\n",
        "\n",
        "        ### 输出格式（严格遵循）：\n",
        "        仅输出JSON格式的字符串数组，每个元素为\"x1,y1,x2,y2\"（左上角x1,y1，右下角x2,y2），无任何额外文字。示例：\n",
        "        [\"ax1,ay1,ax2,ay2\",\"bx1,by1,bx2,by2\"]\n",
        "\n",
        "        ### 坐标规则：\n",
        "        1. 坐标系：以图片左上角为原点(0,0)，x轴向右递增，y轴向下递增\n",
        "        2. 数值标准：采用相对坐标（0-1000整数），0为最左/最上，1000为最右/最下（需符合图片比例）\n",
        "        3. 有效性：确保x1 < x2、y1 < y2，且所有坐标在0-1000范围内\n",
        "\n",
        "        ### 核心要求：\n",
        "        - **比例匹配**：边界框的宽高比（x2-x1 : y2-y1）必须接近主体本身的自然宽高比\n",
        "        - **中心一致**：物体的中心和边界框的中心应尽量重合，\n",
        "        - **边框接近**：框的上、下、左、右边缘均需**紧挨**主体的自然轮廓，刚好把主体框住，与主体边缘贴合没有缝隙\n",
        "\n",
        "        ### 错误规避：\n",
        "        - 边缘离主体过远，导致框内包含大量空白\n",
        "        - 边缘切割主体，导致主体部分缺失\n",
        "        \"\"\"\n",
        " )\n",
        "   \n",
        "# ====== 工具函数 =========\n",
        "def get_image_size(image_path: str) -> Tuple[int, int]:\n",
        "    with Image.open(image_path) as img:\n",
        "        return img.size  # (w, h)\n",
        "\n",
        "\n",
        "def image_to_base64(image_path: str) -> str:\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "\n",
        "def _clamp(v: int, low: int, high: int) -> int:\n",
        "    return max(low, min(v, high))\n",
        "\n",
        "\n",
        "def _to_int2(pt: List[Any]) -> Optional[Tuple[int, int]]:\n",
        "    if not isinstance(pt, (list, tuple)) or len(pt) != 2:\n",
        "        return None\n",
        "    try:\n",
        "        x = int(round(float(pt[0])))\n",
        "        y = int(round(float(pt[1])))\n",
        "        return x, y\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def validate_relative_bbox(bbox: Dict[str, Any]) -> bool:\n",
        "    \"\"\"\n",
        "    校验相对坐标 0..1000，x1<x2, y1<y2\n",
        "    \"\"\"\n",
        "    tl = _to_int2(bbox.get(\"top_left\"))\n",
        "    br = _to_int2(bbox.get(\"bottom_right\"))\n",
        "    if tl is None or br is None:\n",
        "        return False\n",
        "    x1, y1 = tl\n",
        "    x2, y2 = br\n",
        "    if not (0 <= x1 < x2 <= 1000 and 0 <= y1 < y2 <= 1000):\n",
        "        return False\n",
        "    conf = bbox.get(\"confidence\")\n",
        "    try:\n",
        "        conf = float(conf)\n",
        "    except Exception:\n",
        "        return False\n",
        "    return 0.0 <= conf <= 1.0\n",
        "\n",
        "\n",
        "def rel_to_abs_bbox(bbox: Dict[str, Any], img_size: Tuple[int, int]) -> Tuple[int, int, int, int]:\n",
        "    \"\"\"\n",
        "    将相对 0..1000 的坐标转换为像素坐标（用于可视化）\n",
        "    \"\"\"\n",
        "    w, h = img_size\n",
        "    x1_rel, y1_rel = bbox[\"top_left\"]\n",
        "    x2_rel, y2_rel = bbox[\"bottom_right\"]\n",
        "    x1 = int(round(x1_rel / 1000.0 * w))\n",
        "    y1 = int(round(y1_rel / 1000.0 * h))\n",
        "    x2 = int(round(x2_rel / 1000.0 * w))\n",
        "    y2 = int(round(y2_rel / 1000.0 * h))\n",
        "    # 夹取并保证有效\n",
        "    x1 = _clamp(x1, 0, w - 2)\n",
        "    y1 = _clamp(y1, 0, h - 2)\n",
        "    x2 = _clamp(max(x2, x1 + 1), 1, w - 1)\n",
        "    y2 = _clamp(max(y2, y1 + 1), 1, h - 1)\n",
        "    return x1, y1, x2, y2\n",
        "\n",
        "\n",
        "def _load_font(paths: List[str], size: int) -> ImageFont.FreeTypeFont:\n",
        "    for p in paths:\n",
        "        try:\n",
        "            return ImageFont.truetype(p, size=size)\n",
        "        except Exception:\n",
        "            continue\n",
        "    return ImageFont.load_default()\n",
        "\n",
        "\n",
        "class ImageAnnotator:\n",
        "    def __init__(self, image_path: str):\n",
        "        \"\"\"初始化标注器，加载图片并准备绘制对象\"\"\"\n",
        "        # 只加载一次图片\n",
        "        self.image_path = image_path\n",
        "        self.img = Image.open(image_path)\n",
        "        # 转换为RGBA以支持透明图层\n",
        "        if self.img.mode != \"RGBA\":\n",
        "            self.img = self.img.convert(\"RGBA\")\n",
        "        # 创建绘制对象\n",
        "        self.draw = ImageDraw.Draw(self.img)\n",
        "        # 加载字体\n",
        "        self.font = _load_font(FONT_PATHS, FONT_SIZE)\n",
        "        print(\"字体加载:\",self.font)\n",
        "\n",
        "\n",
        "    def add_annotation(self, bbox_abs: Tuple[int, int, int, int], label: str = \"crop\"):\n",
        "        \"\"\"添加一个标注（可多次调用）\"\"\"\n",
        "        x1, y1, x2, y2 = bbox_abs\n",
        "        \n",
        "        # 绘制边界框\n",
        "        self.draw.rectangle([x1, y1, x2, y2], outline=(255, 0, 0, 255), width=2)\n",
        "        \n",
        "        # 绘制居中标签\n",
        "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "        l, t, r, b = self.draw.textbbox((0, 0), label, font=self.font)\n",
        "        tw, th = r - l, b - t\n",
        "        pad = 6\n",
        "        rect = [\n",
        "            cx - tw // 2 - pad, \n",
        "            cy - th // 2 - pad, \n",
        "            cx + tw // 2 + pad, \n",
        "            cy + th // 2 + pad\n",
        "        ]\n",
        "        W, H = self.img.size\n",
        "        \n",
        "        # 调整标签位置避免超出图像边界\n",
        "        dx = -min(0, rect[0]) + min(0, W - rect[2])\n",
        "        dy = -min(0, rect[1]) + min(0, H - rect[3])\n",
        "        rect = [rect[0] + dx, rect[1] + dy, rect[2] + dx, rect[3] + dy]\n",
        "        \n",
        "        # 绘制标签背景和文字\n",
        "        self.draw.rectangle(rect, fill=(0, 0, 0, 140))\n",
        "        self.draw.text(\n",
        "            (rect[0] + pad, rect[1] + pad), \n",
        "            label, \n",
        "            fill=(255, 255, 255, 255), \n",
        "            font=self.font\n",
        "        )\n",
        "\n",
        "    def save(self, output_path: str):\n",
        "        \"\"\"保存标注后的图片\"\"\"\n",
        "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "        ext = os.path.splitext(output_path)[1].lower()\n",
        "        \n",
        "        # 处理JPG格式的透明背景问题\n",
        "        if ext in [\".jpg\", \".jpeg\"]:\n",
        "            background = Image.new(\"RGB\", self.img.size, (255, 255, 255))\n",
        "            background.paste(self.img, mask=self.img.split()[3])  # 使用alpha通道作为掩码\n",
        "            background.save(output_path, quality=95)\n",
        "        else:\n",
        "            self.img.save(output_path)\n",
        "        \n",
        "        # 关闭图片（释放资源）\n",
        "        self.img.close()\n",
        "        print(f\"标注后的图像已保存至 {output_path}\")\n",
        "\n",
        "\n",
        "def call_model(image_b64: str, description: str) -> Optional[Dict[str, Any]]:\n",
        "    sys_prompt = build_system_prompt()\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": sys_prompt},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": f\"主体描述：{description}\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpg;base64,{image_b64}\",\n",
        "                        \"detail\": \"high\",\n",
        "                    },\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": \"请基于以上描述与图像，返回所有符合要求的裁剪框数组。\"},\n",
        "            ],\n",
        "            \"temprature\": 0.0,\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            messages=messages,\n",
        "            model=MODEL_NAME,\n",
        "            response_format=RESPONSE_FORMAT_JSON,\n",
        "        )\n",
        "    except Exception as e:\n",
        "        log(f\"API请求失败: {e}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        content = response.choices[0].message.content.strip()\n",
        "        log(\"原始返回：\", content)\n",
        "        data = json.loads(content)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        log(\"解析JSON失败，请检查API返回内容。报错：\", e)\n",
        "        return None\n",
        "\n",
        "\n",
        "def main():\n",
        "    img_w, img_h = get_image_size(INPUT_IMAGE_PATH)\n",
        "    log(f\"图像大小: {(img_w, img_h)}\")\n",
        "\n",
        "    image_b64 = image_to_base64(INPUT_IMAGE_PATH)\n",
        "\n",
        "    result = call_model(image_b64, SUBJECT_DESCRIPTION)\n",
        "    if not result:\n",
        "        log(\"未能获取有效的分析结果。\")\n",
        "    \n",
        "    annotator = ImageAnnotator(INPUT_IMAGE_PATH)\n",
        "    print(result)\n",
        "\n",
        "    for i, item in enumerate(result, 1):\n",
        "        # 关键修复：字符串按逗号分割，转换为整数元组\n",
        "        x1_rel, y1_rel, x2_rel, y2_rel = map(float, item.split(','))\n",
        "    \n",
        "        # 步骤2：将相对坐标转换为像素坐标（乘以图片宽高）\n",
        "        x1 = int(x1_rel * img_w/1000.0)  # x方向坐标 × 宽度\n",
        "        y1 = int(y1_rel * img_h/1000.0)  # y方向坐标 × 高度\n",
        "        x2 = int(x2_rel * img_w/1000.0)\n",
        "        y2 = int(y2_rel * img_h/1000.0)\n",
        "        \n",
        "        # 转换为元组（像素坐标）\n",
        "        bbox_abs = (x1, y1, x2, y2)\n",
        "        # 传递给add_annotation\n",
        "        annotator.add_annotation(bbox_abs, label=f\"识别_{i}\")\n",
        "    \n",
        "    # 3. 最终保存图片\n",
        "    annotator.save(OUTPUT_IMAGE_PATH)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
